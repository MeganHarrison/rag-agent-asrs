services:
  - type: web
    name: multi-agent-rag-platform
    runtime: python
    plan: starter  # Change to 'pro' for production
    
    # Build configuration
    buildCommand: |
      pip install --no-cache-dir -r requirements.txt &&
      echo "Build completed successfully"
    
    # Start command for multi-agent platform
    startCommand: python -c "from rag_agent.api.multi_agent_app import app; import uvicorn; uvicorn.run(app, host='0.0.0.0', port=int(__import__('os').getenv('PORT', 8000)))"
    
    # Health check
    healthCheckPath: /health
    
    # Scaling for paid tier
    scaling:
      minInstances: 1
      maxInstances: 3  # Auto-scale based on load
      targetMemoryPercent: 70
      targetCPUPercent: 70
    
    # Environment variables
    envVars:
      # Core configuration
      - key: DATABASE_URL
        sync: false
      
      # Multi-agent LLM keys (can use same or different)
      - key: LLM_API_KEY
        sync: false
      - key: FM_GLOBAL_LLM_KEY
        sync: false  # Optional: separate key for FM Global
      - key: GENERAL_LLM_KEY
        sync: false  # Optional: separate key for General RAG
      - key: CODE_LLM_KEY
        sync: false  # Optional: separate key for Code Assistant
      - key: DOCS_LLM_KEY
        sync: false  # Optional: separate key for Document QA
      
      # Model configuration
      - key: LLM_MODEL
        value: gpt-4o-mini  # or gpt-3.5-turbo for cost savings
      - key: EMBEDDING_MODEL
        value: text-embedding-3-small
      - key: LLM_PROVIDER
        value: openai
      - key: LLM_BASE_URL
        value: https://api.openai.com/v1
      
      # Multi-database support (optional)
      - key: FM_GLOBAL_DB_URL
        sync: false  # Separate DB for FM Global data
      - key: GENERAL_DB_URL
        sync: false  # Separate DB for general knowledge
      - key: CODE_DB_URL
        sync: false  # Separate DB for code snippets
      - key: DOCS_DB_URL
        sync: false  # Separate DB for documents
      
      # Performance settings
      - key: MAX_WORKERS
        value: "4"
      - key: CONNECTION_POOL_SIZE
        value: "20"
      - key: CACHE_TTL
        value: "3600"
      
      # CORS configuration
      - key: FRONTEND_URL
        value: https://your-frontend.vercel.app
      
      # Feature flags
      - key: ENABLE_STREAMING
        value: "true"
      - key: ENABLE_METRICS
        value: "true"
      - key: ENABLE_RATE_LIMITING
        value: "true"
      
      # Rate limiting (requests per minute)
      - key: RATE_LIMIT_PER_IP
        value: "60"
      - key: RATE_LIMIT_PER_API_KEY
        value: "1000"

# Database configuration (if using Render PostgreSQL)
databases:
  - name: multi-agent-db
    plan: starter  # Change to 'pro' for production
    databaseName: multiagent
    user: multiagent
    
# Optional: Redis for caching and rate limiting
# services:
#   - type: redis
#     name: multi-agent-cache
#     plan: starter  # Change to 'pro' for production
#     maxmemoryPolicy: allkeys-lru